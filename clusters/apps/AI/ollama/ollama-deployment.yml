apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: web-ui
  labels:
    io.kompose.service: ollama
  name: ollama
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: ollama
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        io.kompose.service: ollama
    spec:
      containers:
        - env:
          - name: OLLAMA_MODEL
            value: "deepseek-r1:1.5b"
          - name: OLLAMA_NO_THINKING
            value: "true"
          - name: OLLAMA_SYSTEM_PROMPT
            value: "You are DeepSeek-R1, a reasoning model. Provide direct answers without detailed reasoning steps or tags."
          image: ollama/ollama:latest
          name: ollama
          ports:
            - containerPort: 27015
              protocol: TCP
          resources:
            requests:
              cpu: "2000m"
              memory: "2Gi"
            limits:
              cpu: "4000m"
              memory: "10Gi"
              nvidia.com/gpu: "0"
          volumeMounts:
            - mountPath: /root/.ollama
              name: ollama-claim0
      nodeSelector:
        deploygame: deepseek
      restartPolicy: Always
      volumes:
        - name: ollama-claim0
          persistentVolumeClaim:
            claimName: ollama-claim0
